{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamunamah/G4AB2_BED_GradedProject3/blob/main/RRR_1_WineData_prob_Mahalingam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports the load_wine function from the sklearn.datasets module, which is a machine learning library in Python.\n",
        "from sklearn.datasets import load_wine\n",
        "wine_data = load_wine() # object\n"
      ],
      "metadata": {
        "id": "C8k-Gy-ovFAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accesses the \"data\" attribute of the \"wine_data\" object.\n",
        "wine_data.data\n"
      ],
      "metadata": {
        "id": "jVmbTXjGveMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports the pandas library and the load_wine function from the sklearn.datasets module.\n",
        "#•  loads the wine dataset with the load_wine function, which is a built-in dataset in scikit-learn.\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "wine_data = load_wine()\n",
        "\n",
        "\n",
        "# Convert data to pandas dataframe while the feature_names attribute contains the names of the features.\n",
        "wine_df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
        "\n",
        "# Add the target label\n",
        "wine_df[\"target\"] = wine_data.target\n",
        "\n",
        "# Take a preview, by default 5 rows will be displayed\n",
        "wine_df.head()\n"
      ],
      "metadata": {
        "id": "M2SrVuKawDBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code snippet is written in Python and uses the Pandas library.\n",
        "#• display the information of wine data using the wine_df.info() function is called on a Pandas DataFrame called wine_df.\n",
        "wine_df.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "gN1jO9xBxGOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call the describe() method on the wine_df DataFrame.\n",
        "wine_df.describe()\n",
        "\n"
      ],
      "metadata": {
        "id": "oGGZSzlKx7_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display the last five rows of the wine_df DataFrame.\n",
        "wine_df.tail()"
      ],
      "metadata": {
        "id": "Aw4FzymZ06QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code performs feature scaling on the wine dataset using the StandardScaler from the scikit-learn library.\n",
        "# import StandardScaler from sklearn.preprocessing.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Split data into features and label\n",
        "X = wine_df[wine_data.feature_names].copy() #input data\n",
        "y = wine_df[\"target\"].copy() #output data\n",
        "\n",
        "# Instantiate scaler and fit on features\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "\n",
        "\n",
        "# Transform features\n",
        "X_scaled = scaler.transform(X.values)\n",
        "\n",
        "# View first instance\n",
        "print(X_scaled[0])"
      ],
      "metadata": {
        "id": "AreqhXHU1Lsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code uses the train_test_split function from the sklearn.model_selection module to split the data into training and testing sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train and test\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, train_size = 0.9, random_state = 25)\n",
        "\n",
        "# Check the splits are correct\n",
        "print(f\"Train size: {round(len(X_train_scaled)/len(X)*100)}%Test_size:{round(len(X_test_scaled)/len(X)*100)}%\")\n"
      ],
      "metadata": {
        "id": "NTXG8pxV15qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code imports three different machine learning models from the scikit-learn library: LogisticRegression, SVC, and DecisionTreeClassifier.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Instantiating the models: logistic_regression, svm, and tree.\n",
        "logistic_regression = LogisticRegression()\n",
        "svm = SVC()\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Training the models\n",
        "logistic_regression.fit(X_train_scaled, y_train)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Making predictions with each model\n",
        "log_reg_preds = logistic_regression.predict(X_test_scaled)\n",
        "svm_preds = svm.predict(X_test_scaled)\n",
        "tree_preds = tree.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "t9M35Udp21c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#This code snippet is evaluating the performance of three different machine learning models on a dataset using the classification_report function from the sklearn.metrics module.\n",
        "#• First, the predictions of each model are stored in a dictionary called model_preds, where the keys are the names of the models and the values are the corresponding predictions.\n",
        "#• Then, a for loop is used to iterate through each model in model_preds and print the classification report for that model using the classification_report function.\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model_preds = {\n",
        "    \"Logistic Regression\": log_reg_preds,\n",
        "    \"Support Vector Machine\": svm_preds,\n",
        "    \"Decision Tree\": tree_preds\n",
        "}\n",
        "\n",
        "for model, preds in model_preds.items():\n",
        "    print(f\"{model} Results:\\n{classification_report(y_test, preds)}\", sep=\"\\n\\n\")\n",
        "\n",
        "# Store model predictions in a dictionary\n",
        "# this makes it's easier to iterate through each model\n",
        "# and print the results.\n",
        "\n"
      ],
      "metadata": {
        "id": "DP2EI-x93fVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}